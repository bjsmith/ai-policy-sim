# üñ•Ô∏è Compute: AI Hardware & Semiconductor Capacity

## United States

The United States maintains a dominant position in advanced AI compute infrastructure. By the end of 2025, approximately [3.56 million Hopper H100, H200, and H800 GPUs had been installed worldwide](https://newsletter.semianalysis.com/p/2025-ai-diffusion-export-controls-microsoft-regulatory-capture-oracle-tears), with the vast majority in US data centers and those of close allies. Nvidia's CEO stated that Nvidia would produce [4-5 million AI chips in 2025, double its 2024 production](https://www.cfr.org/article/chinas-ai-chip-deficit-why-huawei-cant-catch-nvidia-and-us-export-controls-should-remain), indicating sustained 50%+ annual growth in GPU availability.

The H100 GPU, released in 2022, represents the current frontier for AI training, featuring [advanced tensor cores and high-bandwidth memory enabling large-scale model training](https://introl.com/blog/ai-export-controls-navigating-chip-restrictions-globally-2025). US companies face minimal restrictions on accessing these chips, though supply constraints and market dynamics create practical limits.

**Model Parameters:** Starting capacity of 3.5M H100-equivalent GPUs, 50% annual growth rate reflecting doubling capacity every ~1.7 years, 95% constraint factor representing minimal policy restrictions but some market limitations.

## China

China's access to advanced AI compute faces severe constraints from US export controls. The January 2025 "AI Diffusion Rule" established a [three-tier country classification with China in Tier 3, facing complete bans on H100/H200/Blackwell GPUs](https://www.congress.gov/crs-product/R48642). However, [the Trump administration announced plans in December 2025 to loosen controls by approving H200 sales to China](https://builtin.com/articles/trump-lifts-ai-chip-ban-china-nvidia), though implementation remained uncertain.

To circumvent restrictions, Nvidia created the H20, a deliberately downgraded chip compliant with export rules. [Nvidia shipped more than 1.46 million H20 chips to China](https://newsletter.semianalysis.com/p/2025-ai-diffusion-export-controls-microsoft-regulatory-capture-oracle-tears), though the H20 offers only ~30% of H100 performance due to reduced memory bandwidth and processing power. China's domestic alternative, [Huawei's chips, could produce 200,000-300,000 units in 2025 due to high-bandwidth memory shortages](https://www.cfr.org/article/chinas-ai-chip-deficit-why-huawei-cant-catch-nvidia-and-us-export-controls-should-remain), with performance well below H100 standards.

Beyond legal channels, [smuggling operations through Southeast Asia expose the limits of export controls](https://www.tomshardware.com/pc-components/gpus/nvidias-biggest-sea-customer-exposes-the-limits-of-us-ai-export-controls), though exact volumes remain unknown.

**Model Parameters:** Starting capacity of 0.6M H100-equivalent GPUs (1.46M H20 at ~30% performance + ~200K domestic chips at lower capability), 35% annual growth rate reflecting aggressive domestic development but technology gap, 45% constraint factor representing heavy export control impacts limiting access to frontier hardware.
